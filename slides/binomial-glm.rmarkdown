---
title: Binomial GLM
format:
    minimal-revealjs:
        df-print: default
execute: 
  echo: true
---

```{r}
#| label: setup
#| include: false
#| message: false
#| warning: false

library(here)
library(lme4)      # for mixed-models
library(tidyverse) # for data manipulation
library(ggplot2)   # plotting

dat <- readRDS(here("data/shimizu2024.rds"))
```

```{=html}
<style>
    .hg {
        background-color: yellow;
    }
</style>
```

```{r}
#| label: functions
#| include: false

compare <- function(x) {
  if(is.null(attributes(x)$dimnames)){
    names(x) <- 1:length(x)
  }
  all_comp <- combn(x, 2, simplify = FALSE)
  out <- vector(mode = "numeric", length = length(all_comp))

  for(i in 1:length(all_comp)){
    comp <- all_comp[[i]]
    ors <- or(comp[1], comp[2])
    out[i] <- ors
  }

  names(out) <- sapply(all_comp, function(x) paste(names(x), collapse = " / "))
  out
}

style_output <- function(x, lines, class = "hg"){
  x <- capture.output(x)
  x <- htmltools::htmlEscape(x)
  x[lines] <- sprintf("<span class='%s'>%s</span>", class, x[lines])
  cat("<pre><code>")
  cat(x, sep = "\n")
  cat("</code></pre>")
}
```

```{r}
#| label: ggplot2
#| include: false

mtheme <- function(){
    theme_minimal(20) +
        theme(legend.position = "bottom",
              legend.title = element_blank())
}

theme_set(mtheme())
```

## Logistic distribution and binomial

## Example: @Shimizu2024-xl

@Shimizu2024-xl investigated the processing of emotional faces.

- 6 basic emotions: anger, disgust, fear, happiness, sadness and surprise
- intensity in % (from 10% to 100% in steps of 10%)
- 71 participants
- 377 faces (males and females of different identities)
- forced-choice procedure with 7 options (6 emotions + neutral). Chance level at $1/7 = 0.14$.

## @Shimizu2024-xl dataset

We did some pre-processing for the purpose of this example. The original dataset can be found at {{< ai osf >}} [osf.io/zhtbj/](https://osf.io/zhtbj/).

You can download the dataset for this example at this [link](../data/shimizu2024.rds). It is an `rds` file and you can open it using:

```{r}
#| eval: false
#| echo: true

dat <- readRDS("shimizu.rds")
```

Then we can load some packages:

```{r}
#| eval: false

library(lme4)      # for mixed-models
library(tidyverse) # for data manipulation
library(ggplot2)   # plotting
```

## Exploring

For the purpose if this workshop, we will focus on a single subject (otherwise we should use a mixed-effects model). We also select only the relevant columns.

```{r}
dat <- subset(dat, id == 22)
dat <- dat[, c("id", "age", "intensity", "emotion_lbl", "response_lbl", "acc")]
dat
```

## Exploring

- We have `r nrow(dat)` trials and `r ncol(dat)` columns. 
- The `intensity` is the intensity (from 10% to 100%) of the facial expression. `emotion_lbl` is the emotion and `response_lbl` is the response. 
- When `emotion_lbl = response_lbl` the `acc = 1` namely a correct response.

## Exploring

We can calculate the average accuracy for each emotion. Clearly there is a big difference with `fear` being the hardest one and `surprise` the easiest. We remove `neutral` because we have no associated intensity

```{r}
dat |> 
  group_by(emotion_lbl) |> 
  summarise(p = mean(acc),
            n = n()) |> 
  arrange(desc(p))

dat <- filter(dat, emotion_lbl != "neutral")
```

## Exploring

Also for intensity, there is a clear increasing pattern. In this specific subject, the highest intensities are not clearly distinguished (maybe a non-linear pattern).

```{r}
dat |> 
  group_by(intensity) |> 
  summarise(p = mean(acc),
            n = n()) |> 
  arrange(desc(p))
```

## Exploring, plots

```{r}
#| output-location: slide

dat |> 
  group_by(emotion_lbl) |> 
  summarise(p = mean(acc),
            n = n()) |> 
  ggplot(aes(x = fct_reorder(emotion_lbl, p), y = p)) + 
  geom_point(size = 4) +
  geom_line(group = 1) +
  ylim(c(0, 1)) +
  xlab("Emotion") +
  ylab("Accuracy") +
  geom_hline(yintercept = 1/7, lty = "dotted")
```

## Exploring, plots

```{r}
#| output-location: slide

dat |> 
  group_by(intensity) |> 
  summarise(p = mean(acc),
            n = n()) |> 
  arrange(desc(p)) |> 
  ggplot(aes(x = intensity, y = p)) + 
  geom_point(size = 4) +
  geom_line() +
  ylim(c(0, 1)) +
  xlab("Intensity (%)") +
  ylab("Accuracy") +
  geom_hline(yintercept = 1/7, lty = "dotted")
```

## Exploring, plots

We have few trials but we can also explore the interaction between emotion and intensity. There are some emotions where the rate of increase in accuracy as a function of the emotion is faster compared to others.

```{r}
#| output-location: slide

dat |> 
  group_by(intensity, emotion_lbl) |> 
  summarise(p = mean(acc)) |> 
  ggplot(aes(x = intensity, y = p, color = emotion_lbl)) +
  geom_point(size = 4) +
  geom_line()
```

## Exploring, odds and odds ratios

We can start exploring the effects calcualting odds and odds ratios.

```{r}
odds <- function(p) p / (1 - p)
or <- function(pn, pd) odds(pn) / odds(pd)
```

```{r}
#| collapse: true

(p_anger <- mean(dat$acc[dat$emotion_lbl == "anger"]))
(p_surprise <- mean(dat$acc[dat$emotion_lbl == "surprise"]))

odds(p_anger)
odds(p_surprise)

or(p_surprise, p_anger)
```

## Exploring, odds and odds ratios

We can also create a contingency table:

```{r}
table(dat$acc, dat$emotion_lbl)
(all_p <- tapply(dat$acc, dat$emotion_lbl, FUN = mean))
odds(all_p)
```

When the odds are lower than 1, the probability of success is lower than the probability of failure. When the odds are greater than 1 the probability of success is higher.

## Exploring, odds and odds ratios

We can also calculate all the possible comparisons. Note that depending on the numerator/denominator the odds ratio is different but we can simply take the inverse to switch numerator and numerator. Interpreting odds ratio > 1 is usually more intutive.

```{r}
#| echo: false

compare(
    all_p
) |> round(3)
```

For example, `happiness / sadness ~ 2.04` means that the odds (not the probability) of a correct response is 2 times higher for happy faces compared to sad faces. 

# Model

## The `glm` function

In R we can fit a GLM with the `glm` function. The syntax is the same as the `lm` (for standard linear models). We only need to specify the **random component** and the **link function**.

```{r}
#| eval: false

glm(y ~ x1 + x2 + x3 * x4, # systematic component (linear predictor)
    data = data,
    family = binomial(link = "logit")) # random component and link function
```

Clearly, the `y` in this example need to be consistent with the chosen family. In this case the model is expecting a 0-1 vector. If we provide labels (characters) or number > 1 or < 0 the function will fail.

::: {.callout-note}
A `glm` with `family = gaussian(link = "identity")` is the same as running a `lm`. Internally `glm` calls `lm` in this case.
:::

## The null model

We can start with the easiest model that is a model without the systematic component (with no predictors).

```{r}
fit0 <- glm(acc ~ 1, data = dat, family = binomial(link = "logit"))
summary(fit0)
```

## The null model

![](img/fit0_summary.png)

## The null model, formally

$$
\eta_i = \beta_0
$$

$$
p_i = g^{-1}(\eta_i) = g^{-1}(\beta_0)
$$

$g^{-1}(\cdot)$ is the inverse-logit link:

$$
p_i = \frac{e^{\beta_0}}{1 + e^{\beta_0}}
$$

In other terms, the probability can be calculated inverting the logit link function evaluated on the linear predictor $\eta$. In this case $\eta$ only contains $\beta_0$.

## The null model, interpretation

In this case, the intercept is `r round(coef(fit0)[1], 3)`. The intercept is the expected value (i.e., the mean) of `y` (accuracy here) when everthing is zero. In this case $\beta_0$ is just the (logit transformed) overall accuracy.

```{r}
b0 <- coef(fit0)["(Intercept)"]

exp(b0) / (1 + exp(b0)) # inverse logit
plogis(b0)              # directly with the dedicated function
mean(dat$acc)           # average accuracy
log(odds(mean(dat$acc))) # probability to logit
qlogis(mean(dat$acc)) # probability to logit with the dedicated function
```

## Categorical predictor, emotion

Then we can include `emotion_lbl` as predictor. Let's see what happens:

```{r}
fit_em <- glm(acc ~ emotion_lbl, data = dat, family = binomial(link = "logit"))
summary(fit_em)
```

## Categorical predictor, emotion

Now we have 6 coefficients. As in standard linear models, by default, categorical predictors are transformed into dummy variables:

```{r}
unique(model.matrix(~ emotion_lbl, data = dat))
```

The intercept is the reference level (in this case `anger`) and the other 5 coefficients represent the comparison between all emotions vs anger.

## Categorical predictor, emotion {.smaller}

Remember that we are working on the link-function space. For this reason comparisons are expressed in logit. For example, $\beta_1$ (`emotion_lbldisgust`) is the comparison between `disgust` and `anger`. Formally:

$$
\beta_1 = \mbox{logit}(p(y = 1 | \mbox{disgust})) - \mbox{logit}(p(y = 1 | \mbox{anger}))
$$

But the logit is the logarithm of the odds (let's call $p_a$ and $p_d$ anger and disgust respectively)

$$
\log{\frac{p_d}{1 - p_d}} - \log{\frac{p_a}{1 - p_a}}
$$

A difference of logs can be expressed as the log of the ratio:

$$
\log{\frac{\frac{p_d}{1 - p_d}}{\frac{p_a}{1 - p_a}}}
$$

Finally we can take the exponential to remove the log:

$$
e^{\log{\frac{\frac{p_d}{1 - p_d}}{\frac{p_a}{1 - p_a}}}} = \frac{\frac{p_d}{1 - p_d}}{\frac{p_a}{1 - p_a}}
$$

This is exactly the odds ratio! This means that taking the exponential of $\beta_1$ returns the estimated odds ratio for that comparison.

## Categorical predictor

```{r}
coef(fit_em)
exp(coef(fit_em))
```

Comparing with the manual calculation:

```{r}
p_d <- mean(dat$acc[dat$emotion_lbl == "disgust"])
p_a <- mean(dat$acc[dat$emotion_lbl == "anger"])

or(p_d, p_a)
```

## Categorical predictor, main effect of `emotion`

We can also assess the effect of `emotion_lbl` using a Likelihood Ratio Test (LRT). Basically we can compare the model with or without the `emotion_lbl` predictor. Using the LRT we are setting the effect of `emotion_lbl` to zero. This means that the null hypothesis is that all possible contrasts among emotions are zero. 

```{r}
anova(fit0, fit_em) # comparing two models
car::Anova(fit_em)  # using the car::Anova
```

## Categorical predictor, specific contrasts of `emotion` levels

We can also test some specific contrasts using the `emmeans` or the `multcomp` package. For example:

```{r}
library(emmeans)
mm <- emmeans(fit_em, ~ emotion_lbl)
mm
```

These are called **e**stimated **m**rginal **means**. Importantly, the `emmeans` package use the model and not the data. Marginal means will depends on the fitted model.

## Categorical predictor, specific contrasts of `emotion` levels

We would expect estimated probabilities but we have values in logit (this is why we have negative values). We can also transform the logit into probabilities:

```{r}
#| eval: false

emmeans(fit_em, ~ emotion_lbl, type = "response")
```

```{r}
#| echo: false
#| output: asis

emmeans(fit_em, ~ emotion_lbl, type = "response") |> 
    style_output(10, "hg")
```

## What `emmeans` is doing?

To understand what `emmeans` is doing we need to introduce the term prediction. Given the predictors we ask the model the predicted logit or probability.

```{r}
# prediction for the first 5 trials. 
# The best prediction of the model is the (logit) mean

head(predict(fit0, type = "link"))

# prediction for the first 5 trials. 
# the prediction depend on the emotion

head(predict(fit_em, type = "link")) 
head(predict(fit_em, type = "response")) 
head(plogis(predict(fit_em, type = "link"))) # same
```

## What `emmeans` is doing?

For example, to know what is the predicted accuracy for `anger` and `disgust` we can do:

```{r}
predict(fit_em, newdata = data.frame(emotion_lbl = c("anger", "disgust")), type = "response")
```

Or manually:

```{r}
B <- coef(fit_em)
c(
    plogis(B["(Intercept)"]), # anger
    plogis(B["(Intercept)"] + B["emotion_lbldisgust"]) # disgust
)
```

On the logit scale, we can do linear combinations of coefficients. This is not valid on the probability scale, this is the reason why we need the link function.

## What `emmeans` is doing?

For reproducing the entire `emmeans` output we just need to provide all emotions into `newdata = `

```{r}
nd <- data.frame(emotion_lbl = unique(dat$emotion_lbl))
data.frame(predict(fit_em, newdata = nd, se = TRUE, type = "response"))
```

## Contrasts with `emmeans`

We can also compute all contrasts across emotions:

```{r}
# or emmeans(fit_em, pairwise ~ emotion_lbl)
pairs(mm, p.adjust = "bonferroni")
```

Be careful to the multiple comparison approach! You can use the `p.adjust =` argument and choose an appropriate method.

## Contrasts with `emmeans`

Some of these contrasts are also the model parameters:

```{r}
#| echo: false
#| output: asis

pp <- pairs(mm, p.adjust = "bonferroni")
style_output(pp, 2:6, "hg")
```

## Contrasts with `emmeans`

You can also express the contrasts into the probability space. We are just taking the exponential thus transforming differences of logit into odds ratios.

```{r}
pairs(mm, type = "response")
```

Notice that: *Tests are performed on the log odds ratio scale*

## Custom contrasts

Clearly you can also provide custom contrasts like `contr.sum()` or `MASS::contr.sdiff()` (for comparing the next level with the previous level). For an overview about contrasts coding see @Granziol2025-sy and @Schad2020-ht.

```{r}
contrast(mm, "consec") # consec ~ MASS::contr.sdif()
# see ?emmeans::contrast
```

## References
